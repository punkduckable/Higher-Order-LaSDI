{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67dad03-9d76-4891-82ff-7e19d1369a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "import  numpy               as      np\n",
    "from    matplotlib.colors   import  LinearSegmentedColormap\n",
    "import  matplotlib.pyplot   as      plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f4313",
   "metadata": {},
   "source": [
    "# Overall workflow and training\n",
    "\n",
    "Data generation/training can be performed by built-in executable `lasdi`. For this example of Burgers 1D equation, you can simply run on command-line terminal:\n",
    "```\n",
    "lasdi burgers1d.yml\n",
    "```\n",
    "\n",
    "The workflow can be also manually constructed for those who prefer python scripts and for prototyping. Following code snippets show the high-level view of the workflow in the executable `lasdi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ead8f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:48:28.242 - Initialize:Initialize_Trainer:88 - INFO - Initializing Trainer (gplasdi)\n",
      "18:48:28.242 - InputParser:__init__:52 - INFO - Initializing InputParser (param_space_input)\n",
      "18:48:28.243 - ParameterSpace:__init__:173 - INFO - Initializing a ParameterSpace object with parameters ['a', 'w']\n",
      "18:48:28.243 - ParameterSpace:__init__:181 - INFO - The training set has 4 parameter combinations\n",
      "18:48:28.243 - ParameterSpace:__init__:189 - INFO - The testing set has 25 parameter combinations\n",
      "18:48:28.244 - Initialize:Initialize_Physics:226 - INFO - Initializing Physics (burgers1d)\n",
      "18:48:28.244 - InputParser:__init__:52 - INFO - Initializing InputParser (burgers1d_input)\n",
      "18:48:28.244 - InputParser:getInput:137 - WARNING - InputParser Warning: datatype is not checked.\n",
      " key: ['simulation_time']\n",
      " value type: <class 'float'>\n",
      "18:48:28.244 - Initialize:Initialize_Model:168 - INFO - Initializing Model (pair)\n",
      "18:48:28.245 - Model:__init__:592 - INFO - Initializing an Autoencoder_Pair...\n",
      "18:48:28.245 - Model:__init__:612 - INFO - Initializing the Displacement Autoencoder...\n",
      "18:48:28.245 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "18:48:28.246 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "18:48:28.247 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 100, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "18:48:28.247 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "18:48:28.248 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 100, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "18:48:28.248 - Model:__init__:617 - INFO - Initializing the Velocity Autoencoder...\n",
      "18:48:28.249 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "18:48:28.249 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "18:48:28.250 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 100, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "18:48:28.250 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "18:48:28.251 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 100, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "18:48:28.251 - DampedSpring:__init__:67 - INFO - Initializing a DampedSpring object with dim = 5, nt = 1001\n",
      "18:48:28.251 - InputParser:__init__:52 - INFO - Initializing InputParser (spring_input)\n",
      "18:48:28.251 - InputParser:getInput:129 - WARNING - <class 'str'> does not match the type with the fallback value <class 'int'>!\n",
      "18:48:28.252 - InputParser:getInput:130 - WARNING - fallback is 1, val = fro, and keys = ['coef_norm_order']\n",
      "18:48:28.252 - InputParser:getInput:137 - WARNING - InputParser Warning: datatype is not checked.\n",
      " key: ['coef_norm_order']\n",
      " value type: <class 'str'>\n",
      "18:48:28.252 - GPLaSDI:__init__:124 - INFO - Initializing a GPLaSDI object\n",
      "18:48:28.619 - __main__:<module>:44 - INFO - Training with 28000 epochs\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmax_iter);\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# generate initial training/test data\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mPick_Samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     48\u001b[0m Run_Samples(trainer, config);\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# initial training given training data\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Sample.py:58\u001b[0m, in \u001b[0;36mPick_Samples\u001b[0;34m(trainer, config)\u001b[0m\n\u001b[1;32m     54\u001b[0m     new_sample  : numpy\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mparam_space\u001b[38;5;241m.\u001b[39mtrain_space;\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# If this is not the initial step, then we need to use greedy sampling to pick the new \u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# combination of parameter values.\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     new_sample  : numpy\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_new_sample_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     59\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mparam_space\u001b[38;5;241m.\u001b[39mappendTrainSpace(new_sample);\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Now that we know the new points we need to generate simulations for, we need to get ready to\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# actually run those simulations.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/GPLaSDI.py:411\u001b[0m, in \u001b[0;36mBayesianGLaSDI.get_new_sample_point\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03mThis function finds the element of the testing set whose corresponding latent dynamics \u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03mgives the highest variance FOM time series. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03mthe j'th parameter in the new sample.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_Test[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)       \u001b[38;5;241m>\u001b[39m  \u001b[38;5;241m0\u001b[39m);\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_Test[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)       \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space\u001b[38;5;241m.\u001b[39mn_test());\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_coefs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]     \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space\u001b[38;5;241m.\u001b[39mn_train());\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# Imports \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import  os;\n",
    "import  sys;\n",
    "src_path    : str = os.path.join(os.path.abspath(os.path.pardir), \"src\");\n",
    "utils_path  : str = os.path.join(src_path, \"Utilities\");\n",
    "sys.path.append(src_path);\n",
    "sys.path.append(utils_path);\n",
    "\n",
    "import  yaml;\n",
    "import  logging;\n",
    "\n",
    "from    Sample      import  Run_Samples, Pick_Samples;\n",
    "from    Initialize  import  Initialize_Trainer;\n",
    "from    Logging     import  Initialize_Logger, Log_Dictionary;\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Setup\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Set up the logger\n",
    "Initialize_Logger(logging.INFO);\n",
    "LOGGER  : logging.Logger    = logging.getLogger(__name__);\n",
    "\n",
    "# Load the configuration.\n",
    "cfg_file : str = 'burgers1d.yml';\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config : dict = yaml.safe_load(f);\n",
    "Log_Dictionary(LOGGER = LOGGER, D = config, level = logging.DEBUG);\n",
    "\n",
    "# Setup the trainer\n",
    "trainer, param_space, physics, autoencoder, sindy = Initialize_Trainer(config);\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Train\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "LOGGER.info(\"Training with %d epochs\" % trainer.max_iter);\n",
    "\n",
    "# generate initial training/test data\n",
    "Pick_Samples(trainer, config);\n",
    "Run_Samples(trainer, config);\n",
    "\n",
    "# initial training given training data\n",
    "trainer.train();\n",
    "\n",
    "while (trainer.restart_iter < trainer.max_iter):\n",
    "    if (trainer.restart_iter <= trainer.max_greedy_iter):\n",
    "        # perform greedy sampling to pick up new samples\n",
    "        Pick_Samples(trainer, config);\n",
    "        # update training data with newly picked samples\n",
    "        Run_Samples(trainer, config);\n",
    "\n",
    "    # train over given training data\n",
    "    trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffced1",
   "metadata": {},
   "source": [
    "If you ran the command instead, a restart file is saved at the end of the training, which can be loaded for post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4966aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src directory to the search path\n",
    "import  os;\n",
    "import  sys;\n",
    "src_path    : str = os.path.join(os.path.abspath(os.path.pardir), \"src\");\n",
    "sys.path.append(src_path);\n",
    "\n",
    "import  yaml\n",
    "from    ParameterSpace  import  ParameterSpace;\n",
    "from    Initialize      import  Initialize_Trainer;\n",
    "\n",
    "# Specify the restart file you have.\n",
    "filename = 'lasdi_10_01_2024_17_09.npy'\n",
    "\n",
    "cfg_file = 'burgers1d.yml'\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "restart_file = np.load(filename, allow_pickle=True).item()\n",
    "\n",
    "trainer, param_space, physics, autoencoder, sindy = Initialize_Trainer(config, restart_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42758da9",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf48489",
   "metadata": {},
   "source": [
    "Load data for post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdac0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = trainer.best_coefs\n",
    "X_Train = trainer.X_Train\n",
    "X_Test = trainer.X_Test\n",
    "\n",
    "param_train = param_space.train_space\n",
    "param_grid = param_space.test_space\n",
    "test_meshgrid = param_space.test_meshgrid\n",
    "test_grid_sizes = param_space.test_grid_sizes\n",
    "n_init = param_space.n_init_trains\n",
    "\n",
    "n_a_grid, n_w_grid = test_grid_sizes\n",
    "a_grid, w_grid = test_meshgrid\n",
    "\n",
    "t_grid = physics.t_grid\n",
    "x_grid = physics.x_grid\n",
    "t_mesh, x_mesh = np.meshgrid(t_grid, x_grid)\n",
    "Dt, Dx = physics.dt, physics.dx\n",
    "\n",
    "time_dim, space_dim = t_grid.shape[0], x_grid.shape[0]\n",
    "\n",
    "n_coef = sindy.ncoefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6e720",
   "metadata": {},
   "source": [
    "They can be also loaded directly from restart file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = restart_file['trainer']['best_coefs']\n",
    "X_Train = restart_file['trainer']['X_Train']\n",
    "X_Test = restart_file['trainer']['X_Test']\n",
    "\n",
    "paramspace_dict = restart_file['parameters']\n",
    "param_train = paramspace_dict['train_space']\n",
    "param_grid = paramspace_dict['test_space']\n",
    "test_meshgrid = paramspace_dict['test_meshgrid']\n",
    "test_grid_sizes = paramspace_dict['test_grid_sizes']\n",
    "n_init = paramspace_dict['n_init']\n",
    "\n",
    "n_a_grid, n_w_grid = test_grid_sizes\n",
    "a_grid, w_grid = test_meshgrid\n",
    "\n",
    "physics_dict = restart_file['physics']\n",
    "t_grid = physics_dict['t_grid']\n",
    "x_grid = physics_dict['x_grid']\n",
    "t_mesh, x_mesh = np.meshgrid(t_grid, x_grid)\n",
    "Dt = physics_dict['dt']\n",
    "Dx = physics_dict['dx']\n",
    "\n",
    "time_dim, space_dim = t_grid.shape[0], x_grid.shape[0]\n",
    "n_coef = restart_file['latent_dynamics']['ncoefs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262a0c3",
   "metadata": {},
   "source": [
    "## Gaussian-process uncertainty evaluation\n",
    "We evaluated the uncertainties of latent dynamics coefficients over 2d parameter space, with samples from GP prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaussianProcess        import  fit_gps, eval_gp\n",
    "from Simulate               import  sample_roms, average_rom\n",
    "from lasdi.postprocess      import  compute_errors\n",
    "\n",
    "n_samples = 20\n",
    "autoencoder.cpu()\n",
    "\n",
    "gp_dictionnary = fit_gps(param_space.train_space, coefs)\n",
    "\n",
    "Zis_samples = sample_roms(autoencoder, physics, sindy, gp_dictionnary, param_grid, n_samples)\n",
    "Zis_mean = average_rom(autoencoder, physics, sindy, gp_dictionnary, param_grid)\n",
    "\n",
    "X_pred_mean = autoencoder.decoder(torch.Tensor(Zis_mean)).detach().numpy()\n",
    "X_pred_samples = autoencoder.decoder(torch.Tensor(Zis_samples)).detach().numpy()\n",
    "\n",
    "avg_rel_error = np.zeros(param_grid.shape[0])\n",
    "for k in range(param_grid.shape[0]):\n",
    "    avg_rel_error[k], _ = compute_errors(X_pred_mean[k], physics, X_Test[k].numpy())\n",
    "\n",
    "max_std = np.zeros(param_grid.shape[0])\n",
    "for k in range(param_grid.shape[0]):\n",
    "    max_std[k] = X_pred_samples[k].std(0).max()\n",
    "\n",
    "avg_rel_error = avg_rel_error.reshape([n_w_grid, n_a_grid]).T\n",
    "max_std = max_std.reshape([n_w_grid, n_a_grid]).T\n",
    "\n",
    "gp_pred_mean, gp_pred_std = eval_gp(gp_dictionnary, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31c964",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389cdfb3",
   "metadata": {},
   "source": [
    "Plot mean and standard deviation of coefficient matrix.\n",
    "For SINDy of dimension 5, the coefficient matrix has a shape of (6, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasdi.postprocess import plot_gp2d\n",
    "\n",
    "plot_gp2d(a_grid, w_grid, gp_pred_mean.reshape([n_a_grid, n_w_grid, -1]), gp_pred_std.reshape([n_a_grid, n_w_grid, -1]),\n",
    "          param_train, param_labels=['a', 'w'], plot_shape=[6, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6073807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasdi.postprocess import heatmap2d\n",
    "\n",
    "heatmap2d(avg_rel_error * 100, a_grid[:, 0], w_grid[0], param_train, 4, param_labels=['a', 'w'], title='GPLaSDI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97720b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap2d(max_std * 100, a_grid[:, 0], w_grid[0], param_train, 4, param_labels=['a', 'w'], title=r'max$_{(t,x)}\\sqrt{V[\\tilde{u}_{\\xi^*}]}$   ($\\times10^{-2}$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasdi.postprocess import plot_prediction\n",
    "\n",
    "a, w = 0.9, 1.07\n",
    "param = np.array([[a, w]])\n",
    "true = physics.solve(param[0])\n",
    "true = true.detach().numpy().reshape([physics.grid_size[0], physics.nt]).T\n",
    "scale = 1\n",
    "\n",
    "Z = sample_roms(autoencoder, physics, sindy, gp_dictionnary, param, n_samples)\n",
    "\n",
    "Z_mean = Z[0].mean(0)\n",
    "Z_std = Z[0].std(0)\n",
    "\n",
    "pred = autoencoder.decoder(torch.Tensor(Z)).detach().numpy()\n",
    "pred_std = pred[0].std(0)\n",
    "\n",
    "plot_prediction(param, autoencoder, physics, sindy, gp_dictionnary, n_samples, true, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c629e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaSDI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
