{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493f4313",
   "metadata": {},
   "source": [
    "# Overall workflow and training\n",
    "\n",
    "Data generation/training can be performed by built-in executable `lasdi`. For this example of Burgers 1D equation, you can simply run on command-line terminal:\n",
    "```\n",
    "lasdi burgers1d.yml\n",
    "```\n",
    "\n",
    "The workflow can be also manually constructed for those who prefer python scripts and for prototyping. Following code snippets show the high-level view of the workflow in the executable `lasdi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ead8f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:48.674 - Initialize:Initialize_Trainer:88 - INFO - Initializing Trainer (gplasdi)\n",
      "11:55:48.674 - Initialize:Initialize_Trainer:88 - INFO - Initializing Trainer (gplasdi)\n",
      "11:55:48.674 - Initialize:Initialize_Trainer:88 - INFO - Initializing Trainer (gplasdi)\n",
      "11:55:48.675 - ParameterSpace:__init__:174 - INFO - Initializing a ParameterSpace object with parameters ['a', 'w']\n",
      "11:55:48.675 - ParameterSpace:__init__:174 - INFO - Initializing a ParameterSpace object with parameters ['a', 'w']\n",
      "11:55:48.675 - ParameterSpace:__init__:174 - INFO - Initializing a ParameterSpace object with parameters ['a', 'w']\n",
      "11:55:48.677 - ParameterSpace:__init__:182 - INFO - The training set has 4 parameter combinations\n",
      "11:55:48.677 - ParameterSpace:__init__:182 - INFO - The training set has 4 parameter combinations\n",
      "11:55:48.677 - ParameterSpace:__init__:182 - INFO - The training set has 4 parameter combinations\n",
      "11:55:48.678 - ParameterSpace:__init__:190 - INFO - The testing set has 25 parameter combinations\n",
      "11:55:48.678 - ParameterSpace:__init__:190 - INFO - The testing set has 25 parameter combinations\n",
      "11:55:48.678 - ParameterSpace:__init__:190 - INFO - The testing set has 25 parameter combinations\n",
      "11:55:48.679 - Initialize:Initialize_Physics:226 - INFO - Initializing Physics (burgers1d)\n",
      "11:55:48.679 - Initialize:Initialize_Physics:226 - INFO - Initializing Physics (burgers1d)\n",
      "11:55:48.679 - Initialize:Initialize_Physics:226 - INFO - Initializing Physics (burgers1d)\n",
      "11:55:48.680 - Initialize:Initialize_Model:168 - INFO - Initializing Model (pair)\n",
      "11:55:48.680 - Initialize:Initialize_Model:168 - INFO - Initializing Model (pair)\n",
      "11:55:48.680 - Initialize:Initialize_Model:168 - INFO - Initializing Model (pair)\n",
      "11:55:48.681 - Model:__init__:594 - INFO - Initializing an Autoencoder_Pair...\n",
      "11:55:48.681 - Model:__init__:594 - INFO - Initializing an Autoencoder_Pair...\n",
      "11:55:48.681 - Model:__init__:594 - INFO - Initializing an Autoencoder_Pair...\n",
      "11:55:48.682 - Model:__init__:614 - INFO - Initializing the Displacement Autoencoder...\n",
      "11:55:48.682 - Model:__init__:614 - INFO - Initializing the Displacement Autoencoder...\n",
      "11:55:48.682 - Model:__init__:614 - INFO - Initializing the Displacement Autoencoder...\n",
      "11:55:48.683 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.683 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.683 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.684 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.684 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.684 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.688 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.688 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.688 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.689 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.689 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.689 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.692 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.692 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.692 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.692 - Model:__init__:619 - INFO - Initializing the Velocity Autoencoder...\n",
      "11:55:48.692 - Model:__init__:619 - INFO - Initializing the Velocity Autoencoder...\n",
      "11:55:48.692 - Model:__init__:619 - INFO - Initializing the Velocity Autoencoder...\n",
      "11:55:48.693 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.693 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.693 - Model:__init__:304 - INFO - Initializing an Autoencoder with latent space dimension 5\n",
      "11:55:48.694 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.694 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.694 - Model:__init__:307 - INFO - Initializing the encoder...\n",
      "11:55:48.697 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.697 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.697 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [1001, 200, 200, 50, 50, 5], activation tanh, reshape_shape = [1001] (index 0)\n",
      "11:55:48.698 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.698 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.698 - Model:__init__:314 - INFO - Initializing the decoder...\n",
      "11:55:48.701 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.701 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.701 - Model:__init__:159 - INFO - Initializing a MultiLayerPerceptron with widths [5, 50, 50, 200, 200, 1001], activation tanh, reshape_shape = [1001] (index -1)\n",
      "11:55:48.702 - DampedSpring:__init__:66 - INFO - Initializing a DampedSpring object with dim = 5, n_t = 501\n",
      "11:55:48.702 - DampedSpring:__init__:66 - INFO - Initializing a DampedSpring object with dim = 5, n_t = 501\n",
      "11:55:48.702 - DampedSpring:__init__:66 - INFO - Initializing a DampedSpring object with dim = 5, n_t = 501\n",
      "11:55:48.702 - GPLaSDI:__init__:127 - INFO - Initializing a GPLaSDI object\n",
      "11:55:48.702 - GPLaSDI:__init__:127 - INFO - Initializing a GPLaSDI object\n",
      "11:55:48.702 - GPLaSDI:__init__:127 - INFO - Initializing a GPLaSDI object\n",
      "11:55:48.703 - __main__:<module>:51 - INFO - Training with 12000 epochs\n",
      "11:55:48.703 - __main__:<module>:51 - INFO - Training with 12000 epochs\n",
      "11:55:48.703 - __main__:<module>:51 - INFO - Training with 12000 epochs\n",
      "11:55:48.704 - Sample:Run_Samples:114 - INFO - Adding 4 new parameter combinations to the training set (currently has 0)\n",
      "11:55:48.704 - Sample:Run_Samples:114 - INFO - Adding 4 new parameter combinations to the training set (currently has 0)\n",
      "11:55:48.704 - Sample:Run_Samples:114 - INFO - Adding 4 new parameter combinations to the training set (currently has 0)\n",
      "11:55:48.705 - Sample:Run_Samples:131 - INFO - Adding 25 new parameter combinations to the testing set (currently has 0)\n",
      "11:55:48.705 - Sample:Run_Samples:131 - INFO - Adding 25 new parameter combinations to the testing set (currently has 0)\n",
      "11:55:48.705 - Sample:Run_Samples:131 - INFO - Adding 25 new parameter combinations to the testing set (currently has 0)\n",
      "11:55:48.706 - Physics:generate_solutions:181 - INFO - Generating solution for 4 parameter combinations\n",
      "11:55:48.706 - Physics:generate_solutions:181 - INFO - Generating solution for 4 parameter combinations\n",
      "11:55:48.706 - Physics:generate_solutions:181 - INFO - Generating solution for 4 parameter combinations\n",
      "11:55:48.899 - Physics:generate_solutions:197 - INFO - 1/4 complete\n",
      "11:55:48.899 - Physics:generate_solutions:197 - INFO - 1/4 complete\n",
      "11:55:48.899 - Physics:generate_solutions:197 - INFO - 1/4 complete\n",
      "11:55:49.082 - Physics:generate_solutions:197 - INFO - 2/4 complete\n",
      "11:55:49.082 - Physics:generate_solutions:197 - INFO - 2/4 complete\n",
      "11:55:49.082 - Physics:generate_solutions:197 - INFO - 2/4 complete\n",
      "11:55:49.279 - Physics:generate_solutions:197 - INFO - 3/4 complete\n",
      "11:55:49.279 - Physics:generate_solutions:197 - INFO - 3/4 complete\n",
      "11:55:49.279 - Physics:generate_solutions:197 - INFO - 3/4 complete\n",
      "11:55:49.462 - Physics:generate_solutions:197 - INFO - 4/4 complete\n",
      "11:55:49.462 - Physics:generate_solutions:197 - INFO - 4/4 complete\n",
      "11:55:49.462 - Physics:generate_solutions:197 - INFO - 4/4 complete\n",
      "11:55:49.464 - Physics:generate_solutions:181 - INFO - Generating solution for 25 parameter combinations\n",
      "11:55:49.464 - Physics:generate_solutions:181 - INFO - Generating solution for 25 parameter combinations\n",
      "11:55:49.464 - Physics:generate_solutions:181 - INFO - Generating solution for 25 parameter combinations\n",
      "11:55:49.668 - Physics:generate_solutions:197 - INFO - 1/25 complete\n",
      "11:55:49.668 - Physics:generate_solutions:197 - INFO - 1/25 complete\n",
      "11:55:49.668 - Physics:generate_solutions:197 - INFO - 1/25 complete\n",
      "11:55:49.862 - Physics:generate_solutions:197 - INFO - 2/25 complete\n",
      "11:55:49.862 - Physics:generate_solutions:197 - INFO - 2/25 complete\n",
      "11:55:49.862 - Physics:generate_solutions:197 - INFO - 2/25 complete\n",
      "11:55:50.061 - Physics:generate_solutions:197 - INFO - 3/25 complete\n",
      "11:55:50.061 - Physics:generate_solutions:197 - INFO - 3/25 complete\n",
      "11:55:50.061 - Physics:generate_solutions:197 - INFO - 3/25 complete\n",
      "11:55:50.247 - Physics:generate_solutions:197 - INFO - 4/25 complete\n",
      "11:55:50.247 - Physics:generate_solutions:197 - INFO - 4/25 complete\n",
      "11:55:50.247 - Physics:generate_solutions:197 - INFO - 4/25 complete\n",
      "11:55:50.445 - Physics:generate_solutions:197 - INFO - 5/25 complete\n",
      "11:55:50.445 - Physics:generate_solutions:197 - INFO - 5/25 complete\n",
      "11:55:50.445 - Physics:generate_solutions:197 - INFO - 5/25 complete\n",
      "11:55:50.648 - Physics:generate_solutions:197 - INFO - 6/25 complete\n",
      "11:55:50.648 - Physics:generate_solutions:197 - INFO - 6/25 complete\n",
      "11:55:50.648 - Physics:generate_solutions:197 - INFO - 6/25 complete\n",
      "11:55:50.845 - Physics:generate_solutions:197 - INFO - 7/25 complete\n",
      "11:55:50.845 - Physics:generate_solutions:197 - INFO - 7/25 complete\n",
      "11:55:50.845 - Physics:generate_solutions:197 - INFO - 7/25 complete\n",
      "11:55:51.044 - Physics:generate_solutions:197 - INFO - 8/25 complete\n",
      "11:55:51.044 - Physics:generate_solutions:197 - INFO - 8/25 complete\n",
      "11:55:51.044 - Physics:generate_solutions:197 - INFO - 8/25 complete\n",
      "11:55:51.240 - Physics:generate_solutions:197 - INFO - 9/25 complete\n",
      "11:55:51.240 - Physics:generate_solutions:197 - INFO - 9/25 complete\n",
      "11:55:51.240 - Physics:generate_solutions:197 - INFO - 9/25 complete\n",
      "11:55:51.451 - Physics:generate_solutions:197 - INFO - 10/25 complete\n",
      "11:55:51.451 - Physics:generate_solutions:197 - INFO - 10/25 complete\n",
      "11:55:51.451 - Physics:generate_solutions:197 - INFO - 10/25 complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# generate initial training/test data\u001b[39;00m\n\u001b[1;32m     54\u001b[0m Pick_Samples(trainer, config);\n\u001b[0;32m---> 55\u001b[0m \u001b[43mRun_Samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Fetch the number of testing, training examples.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m n_train : \u001b[38;5;28mint\u001b[39m   \u001b[38;5;241m=\u001b[39m param_space\u001b[38;5;241m.\u001b[39mtrain_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m];\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Sample.py:157\u001b[0m, in \u001b[0;36mRun_Samples\u001b[0;34m(trainer, config)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Do the same thing for the testing points.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (new_tests \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     new_X           : \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]    \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_solutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_test_params\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(trainer\u001b[38;5;241m.\u001b[39mX_Test[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    160\u001b[0m         trainer\u001b[38;5;241m.\u001b[39mX_Test \u001b[38;5;241m=\u001b[39m new_X;\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Physics/Physics.py:187\u001b[0m, in \u001b[0;36mPhysics.generate_solutions\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    184\u001b[0m X_Train : \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m [];\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# Solve the underlying equation using the current set of parameter values.\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     new_X : \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# Now, add this solution to the set of solutions.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(new_X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# should contain one parameter case.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Physics/Burgers1d.py:211\u001b[0m, in \u001b[0;36mBurgers1D.solve\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m# Solve the PDE and then reshape the result to be a 3d tensor with a leading dimension of \u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m# size 1.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mX       : torch.Tensor          = torch.Tensor(solver(u0, self.maxk, self.convergence_threshold, self.n_t - 1, self.spatial_grid_shape[0], self.dt, self.dx));        \u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03mnew_X   : list[torch.Tensor]    = [X.reshape(1, self.n_t, self.spatial_grid_shape[0])];\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m######## REMOVE ME   ||\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m######## REMOVE ME   ||\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Solve the PDE and then reshape the result to be a 3d tensor with a leading dimension of \u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# size 1.\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m X       : torch\u001b[38;5;241m.\u001b[39mTensor  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_t\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_grid_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[43m)\u001b[49m);\n\u001b[1;32m    212\u001b[0m V       : torch\u001b[38;5;241m.\u001b[39mTensor  \u001b[38;5;241m=\u001b[39m Derivative1_Order4(X, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt);\n\u001b[1;32m    214\u001b[0m X       : torch\u001b[38;5;241m.\u001b[39mTensor  \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_grid_shape[\u001b[38;5;241m0\u001b[39m]);\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Physics/Burgers1d.py:349\u001b[0m, in \u001b[0;36msolver\u001b[0;34m(u0, maxk, convergence_threshold, n_t, n_x, Dt, Dx)\u001b[0m\n\u001b[1;32m    346\u001b[0m r \u001b[38;5;241m=\u001b[39m residual_burgers(u[n, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], uw, c, idxn1);\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(maxk):\n\u001b[0;32m--> 349\u001b[0m     J \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43muw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_x\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    350\u001b[0m     duw \u001b[38;5;241m=\u001b[39m spsolve(J, \u001b[38;5;241m-\u001b[39mr);\n\u001b[1;32m    351\u001b[0m     uw \u001b[38;5;241m=\u001b[39m uw \u001b[38;5;241m+\u001b[39m duw;\n",
      "File \u001b[0;32m~/Documents/Projects/Second Order LaSDI/src/Physics/Burgers1d.py:321\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(u, c, idxn1, n_x)\u001b[0m\n\u001b[1;32m    319\u001b[0m data                \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray([diag_comp, subdiag_comp]);\n\u001b[1;32m    320\u001b[0m J                   \u001b[38;5;241m=\u001b[39m spdiags(data, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, n_x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[0;32m--> 321\u001b[0m J[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]            \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mc \u001b[38;5;241m*\u001b[39m u[\u001b[38;5;241m0\u001b[39m];\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m J\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/scipy/sparse/_csr.py:41\u001b[0m, in \u001b[0;36m_csr_base.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     44\u001b[0m         key \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/scipy/sparse/_index.py:108\u001b[0m, in \u001b[0;36mIndexMixin.__setitem__\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrying to assign a sequence to an item\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_intXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, \u001b[38;5;28mslice\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/scipy/sparse/_compressed.py:909\u001b[0m, in \u001b[0;36m_cs_matrix._set_intXint\u001b[0;34m(self, row, col, x)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_intXint\u001b[39m(\u001b[38;5;28mself\u001b[39m, row, col, x):\n\u001b[1;32m    908\u001b[0m     i, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((row, col))\n\u001b[0;32m--> 909\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1033\u001b[0m, in \u001b[0;36m_cs_matrix._set_many\u001b[0;34m(self, i, j, x)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_many\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, j, x):\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sets value at each (i, j) to x\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    Here (i,j) index major and minor respectively, and must not contain\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m    duplicate entries.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m     i, j, M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m   1036\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1021\u001b[0m, in \u001b[0;36m_cs_matrix._prepare_indices\u001b[0;34m(self, i, j)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mbound:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range (< -\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1019\u001b[0m                          (idx, bound))\n\u001b[0;32m-> 1021\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m   1022\u001b[0m j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(np\u001b[38;5;241m.\u001b[39masarray(j, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype))\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m   1023\u001b[0m check_bounds(i, M)\n",
      "File \u001b[0;32m~/miniconda3/envs/LaSDI/lib/python3.10/site-packages/numpy/core/shape_base.py:70\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "# Imports \n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "import  os;\n",
    "import  sys;\n",
    "\n",
    "src_path    : str = os.path.join(os.path.abspath(os.path.pardir), \"src\");\n",
    "utils_path  : str = os.path.join(src_path, \"Utilities\");\n",
    "sys.path.append(src_path);\n",
    "sys.path.append(utils_path);\n",
    "\n",
    "import  random;\n",
    "import  yaml;\n",
    "import  logging;\n",
    "\n",
    "import  torch\n",
    "import  numpy;\n",
    "\n",
    "from    Workflow    import  Save;\n",
    "from    Enums       import  NextStep, Result\n",
    "from    Sample      import  Run_Samples, Pick_Samples;\n",
    "from    Initialize  import  Initialize_Trainer;\n",
    "from    Logging     import  Initialize_Logger, Log_Dictionary;\n",
    "from    Plot        import  Plot_Reconstruction;\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Setup\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Set up the logger\n",
    "Initialize_Logger(logging.INFO);\n",
    "LOGGER  : logging.Logger    = logging.getLogger(__name__);\n",
    "\n",
    "# Load the configuration.\n",
    "cfg_file : str = 'burgers1d.yml';\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config : dict = yaml.safe_load(f);\n",
    "Log_Dictionary(LOGGER = LOGGER, D = config, level = logging.DEBUG);\n",
    "\n",
    "# Setup the trainer\n",
    "trainer, param_space, physics, model, latent_dynamics = Initialize_Trainer(config);\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "# Train\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "LOGGER.info(\"Training with %d epochs\" % trainer.max_iter);\n",
    "\n",
    "# generate initial training/test data\n",
    "Pick_Samples(trainer, config);\n",
    "Run_Samples(trainer, config);\n",
    "\n",
    "\n",
    "\n",
    "# Fetch the number of testing, training examples.\n",
    "n_train : int   = param_space.train_space.shape[0];\n",
    "n_test  : int   = param_space.test_space.shape[0];\n",
    "n_IC    : int   = latent_dynamics.n_IC;\n",
    "\n",
    "# initial training given training data\n",
    "trainer.train();\n",
    "\n",
    "\n",
    "# Select a random parameter combination to investigate.\n",
    "index_plot  : int = random.randrange(0, n_test);\n",
    "print(\"Plotting testing parameter combination number %d (%s = %s)\" % (index_plot, str(param_space.param_names), str(param_space.test_space[index_plot, :])));\n",
    "\n",
    "Plot_Reconstruction(\n",
    "        X_True  = [trainer.X_Test[d][index_plot, ...] for d in range(n_IC)], \n",
    "        model   = trainer.model, \n",
    "        t_grid  = trainer.physics.t_grid, \n",
    "        x_grid  = trainer.physics.x_grid);\n",
    "\n",
    "\n",
    "while (trainer.restart_iter < trainer.max_iter):\n",
    "    if (trainer.restart_iter <= trainer.max_greedy_iter):\n",
    "        # perform greedy sampling to pick up new samples\n",
    "        Pick_Samples(trainer, config);\n",
    "        # update training data with newly picked samples\n",
    "        Run_Samples(trainer, config);\n",
    "\n",
    "    # train over given training data\n",
    "    trainer.train();\n",
    "\n",
    "    # Plot \n",
    "    Plot_Reconstruction(  \n",
    "            X_True  = [trainer.X_Test[d][index_plot, ...] for d in range(n_IC)], \n",
    "            model   = trainer.model, \n",
    "            t_grid  = trainer.physics.t_grid, \n",
    "            x_grid  = trainer.physics.x_grid);\n",
    "\n",
    "\n",
    "# Finally, save!\n",
    "Save(   param_space         = param_space, \n",
    "        physics             = physics, \n",
    "        model               = model, \n",
    "        latent_dynamics     = latent_dynamics, \n",
    "        trainer             = trainer, \n",
    "        next_step           = NextStep.PickSample, \n",
    "        result              = Result.Success,\n",
    "        restart_filename    = None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f092b",
   "metadata": {},
   "source": [
    "If you ran the command instead, a restart file is saved at the end of the training, which can be loaded for post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4966aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src directory to the search path\n",
    "import  os;\n",
    "import  sys;\n",
    "src_path    : str = os.path.join(os.path.abspath(os.path.pardir), \"src\");\n",
    "sys.path.append(src_path);\n",
    "\n",
    "import  yaml\n",
    "from    ParameterSpace  import  ParameterSpace;\n",
    "from    Initialize      import  Initialize_Trainer;\n",
    "\n",
    "# Specify the restart file you have.\n",
    "filename = 'lasdi_10_01_2024_17_09.npy'\n",
    "\n",
    "cfg_file = 'burgers1d.yml'\n",
    "with open(cfg_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "restart_file = numpy.load(filename, allow_pickle = True).item()\n",
    "\n",
    "trainer, param_space, physics, model, latent_dynamics = Initialize_Trainer(config, restart_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42758da9",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf48489",
   "metadata": {},
   "source": [
    "Setup data for post-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdac0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_coef              : int                   = latent_dynamics.n_coefs;\n",
    "n_IC                : int                   = latent_dynamics.n_IC; \n",
    "n_p                 : int                   = param_space.n_p; \n",
    "\n",
    "coefs               : numpy.ndarray         = trainer.best_coefs;           # shape = (n_train, n_coefs).\n",
    "X_Train             : list[torch.Tensor]    = trainer.X_Train;              # len = n_IC. d'th element has shape (n_train, n_t, n_x), holds d'th derivative of fom train solutions\n",
    "X_Test              : list[torch.Tensor]    = trainer.X_Test;               # len = n_IC. d'th element has shape (n_train, n_t, n_x), holds d'th derivative of fom test solutions.\n",
    "\n",
    "param_train         : numpy.ndarray         = param_space.train_space;      # shape = (n_test, n_p)\n",
    "param_test          : numpy.ndarray         = param_space.test_space;       # shape = (n_test, n_p)\n",
    "param_names         : list[str]             = param_space.param_names;\n",
    "\n",
    "test_meshgrid       : tuple[numpy.ndarray]  = param_space.test_meshgrid;    # len = n_p. i'th element is meshgrid for i'th parameter.\n",
    "test_grid_sizes     : list[int]             = param_space.test_grid_sizes;  # len = n_p. i'th element holds the number of values of the i'th parameter in the test set.\n",
    "n_init_train        : int                   = param_space.n_init_train;     # The initial number of combinations of parameters in the training set.\n",
    "n_test              : int                   = param_test.shape[0];\n",
    "n_train             : int                   = param_train.shape[0];\n",
    "\n",
    "t_grid              : numpy.ndarray         = physics.t_grid;               # set of t values at which we evaluate the fom solution\n",
    "x_grid              : numpy.ndarray         = physics.x_grid;               # set of x values at which we evaluate the fom solution.\n",
    "t_mesh, x_mesh                              = numpy.meshgrid(t_grid, x_grid);\n",
    "\n",
    "# Fetch information about the temporal, spatial grids.\n",
    "Dt                  : float                 = physics.dt\n",
    "Dx                  : float                 = physics.dx;\n",
    "n_t                 : int                   = t_grid.shape[0];\n",
    "n_x                 : int                   = x_grid.shape[0];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6e720",
   "metadata": {},
   "source": [
    "They can be also loaded directly from restart file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_coef              : int                   = restart_file['latent_dynamics']['n_coefs'];\n",
    "n_IC                : int                   = restart_file['latent_dynamics']['n_IC'];\n",
    "n_p                 : int                   = restart_file['parameter_space']['n_p'];\n",
    "\n",
    "coefs               : numpy.ndarray         = restart_file['trainer']['best_coefs'];    # shape = (n_train, n_coefs); np = number of combinations of parameters\n",
    "X_Train             : list[torch.Tensor]    = restart_file['trainer']['X_Train'];       # len = n_IC. i'th element has shape (n_train, n_t, ...), holds d'th derivative of fom test solutions.\n",
    "X_Test              : list[torch.Tensor]    = restart_file['trainer']['X_Test'];        # len = n_IC. i'th element has shape (n_test, n_t, ...), holds d'th derivative of fom test solutions.\n",
    "\n",
    "paramspace_dict     : dict                  = restart_file['parameter_space'];          # parameter space save dictionary.\n",
    "param_train         : numpy.ndarray         = paramspace_dict['train_space'];           # shape = (n_train, n_p)\n",
    "param_test          : numpy.ndarray         = paramspace_dict['test_space'];            # shape = (n_test, n_p)\n",
    "param_names         : list[str]             = param_space.param_names;\n",
    "\n",
    "test_meshgrid       : list[int]             = paramspace_dict['test_meshgrid'];         # len = n_p. i'th element is meshgrid for i'th parameter.\n",
    "test_grid_sizes     : list[int]             = paramspace_dict['test_grid_sizes'];       # len = n_p. i'th element holds the number of values of the i'th parameter in the test set.\n",
    "n_init_train        : int                   = paramspace_dict['n_init'];                # The initial number of combinations of parameters in the training set.\n",
    "n_test              : int                   = param_test.shape[0];\n",
    "n_train             : int                   = param_train.shape[0];\n",
    "\n",
    "physics_dict        : dict                  = restart_file['physics'];                  \n",
    "t_grid              : numpy.ndarray         = physics_dict['t_grid'];                   # set of t values at which we evaluate the fom solution\n",
    "x_grid              : numpy.ndarray         = physics_dict['x_grid'];                   # set of x values at which we evaluate the fom solution.\n",
    "t_mesh, x_mesh                              = numpy.meshgrid(t_grid, x_grid);\n",
    "\n",
    "# Fetch information about the temporal, spatial grids.\n",
    "Dt                  : float                 = physics.dt\n",
    "Dx                  : float                 = physics.dx;\n",
    "n_t                 : int                   = t_grid.shape[0];\n",
    "n_x                 : int                   = x_grid.shape[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262a0c3",
   "metadata": {},
   "source": [
    "## Gaussian-process uncertainty evaluation\n",
    "For each combination of parameters, evaluate the coefficient GPs to generate a set of coefficients for the latent dynamics for that parameter combination. Then solve each latent dynamics forward in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to import a few new things.\n",
    "import os;\n",
    "import sys;\n",
    "physics_path : str = os.path.join(os.path.join(os.path.pardir, \"src\"), \"Physics\");\n",
    "sys.path.append(physics_path);\n",
    "\n",
    "from    sklearn.gaussian_process    import  GaussianProcessRegressor;\n",
    "\n",
    "import  Simulate;\n",
    "import  GaussianProcess;\n",
    "from    Physics                     import  Physics;\n",
    "from    Model                       import  Autoencoder, Autoencoder_Pair;\n",
    "\n",
    "# Setup\n",
    "n_samples : int = 20;\n",
    "model.cpu();\n",
    "\n",
    "\n",
    "\n",
    "# Get a GP for each coefficient in the latent dynamics.\n",
    "gp_list         : list[GaussianProcessRegressor]    = GaussianProcess.fit_gps(param_space.train_space, coefs);\n",
    "\n",
    "Zis_samples     : list[numpy.ndarray]   = Simulate.sample_roms(model, physics, latent_dynamics, gp_list, param_test, n_samples); # n_IC elements. Each has shape (n_test, n_samples, n_t, n_z)\n",
    "Zis_mean        : list[numpy.ndarray]   = Simulate.average_rom(model, physics, latent_dynamics, gp_list, param_test);            # n_IC elements. Each has shape (n_test, n_t, n_z).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f0680",
   "metadata": {},
   "source": [
    "Now, decode the latent trajectories and compare them to the test set. Use these values to compute some errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06eee490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the samples through the decoder. The way this works depends on what kind of model we are using. \n",
    "if(isinstance(model, Autoencoder)):\n",
    "    # Decode the mean predictions.\n",
    "    X_pred_mean     : list[numpy.ndarray]   = [model.Decode(torch.Tensor(Zis_mean[0])).detach().numpy()];  # shape = (n_test, n_t, n_x)\n",
    "\n",
    "    # Decode the Zis for each parameter. Note that the decoder expects a 3d tensor of shape \n",
    "    # (n_test, n_t, n_z). We can somewhat abuse this by treating the different samples as different \n",
    "    # parameters. We still need to loop over the number of parameters, however.\n",
    "    X_pred_samples  : list[numpy.ndarray]   = [numpy.empty((n_test, n_samples, n_t, n_x))];\n",
    "    for i in range(n_test):\n",
    "        X_pred_samples[0][i, :, : , :]  = model.Decode(torch.Tensor(Zis_samples[0][i, :, :, :])).detach().numpy();\n",
    "\n",
    "elif(isinstance(model, Autoencoder_Pair)):\n",
    "    # Decode the mean predictions.\n",
    "    Disp_Pred_mean, Vel_Pred_mean           = model.Decode(torch.Tensor(Zis_mean[0]), torch.Tensor(Zis_mean[1]));\n",
    "    X_pred_mean     : list[numpy.ndarray]   = [Disp_Pred_mean.detach().numpy(), Vel_Pred_mean.detach().numpy()];\n",
    "\n",
    "    # Decode the Zis for each parameter. Note that the decoder expects a 3d tensor of shape \n",
    "    # (n_test, n_t, n_z). We can somewhat abuse this by treating the different samples as different \n",
    "    # parameters. We still need to loop over the number of parameters, however.\n",
    "    X_pred_samples  : list[numpy.ndarray]   = [numpy.empty((n_test, n_samples, n_t, n_x)), numpy.empty((n_test, n_samples, n_t, n_x))];\n",
    "    for i in range(n_test):\n",
    "        ith_Disp_Pred, ith_Vel_Pred     = model.Decode(torch.Tensor(Zis_samples[0][i, :, :, :]), torch.Tensor(Zis_samples[1][i, :, :, :]));\n",
    "        X_pred_samples[0][i, :, :, :]   = ith_Disp_Pred.detach().numpy();\n",
    "        X_pred_samples[1][i, :, :, :]   = ith_Vel_Pred.detach().numpy();\n",
    "\n",
    "\n",
    "\n",
    "# Set up arrays to hold the average error between X_pred_mean and X_test, as well as the std of \n",
    "# the predictions.\n",
    "mean_rel_error   : list[numpy.ndarray]   = [];\n",
    "max_std          : list[numpy.ndarray]   = [];\n",
    "for d in range(n_IC):\n",
    "    mean_rel_error.append(  numpy.zeros(n_test, dtype = numpy.float32));\n",
    "    max_std.append(         numpy.zeros(n_test, dtype = numpy.float32));\n",
    "\n",
    "# For each d \\in {0, 1, ... , n_IC - 1} and k \\in { 1, 2, ... , n_test - 1}, find the std of the \n",
    "# frame of the d'th derivative of the fom solution with the k'th combination of parameter values \n",
    "# that has the greatest variance + find the mean error between X_Pred_mean[d][k, ...] and \n",
    "# X_test[d][k, ...].\n",
    "for d in range(n_IC):\n",
    "    for k in range(n_test):        \n",
    "        # Extract the prediction, true values for the d'th component of the fom solution when we use \n",
    "        # the k'th parameter value. These have shape (n_t, n_x).\n",
    "        kth_X_Pred_d            : numpy.ndarray = X_pred_mean[d][k, :, :];\n",
    "        kth_X_Test_d            : numpy.ndarray = X_Test[d][k, :, :].numpy();\n",
    "        \n",
    "        # For each compute the relative error between the predicted and true values of the d'th \n",
    "        # derivative of the fom solution at each time step when we use the k'th combination of \n",
    "        # parameter values.\n",
    "        kth_Relative_Errors_d   : numpy.ndarray = numpy.linalg.norm(kth_X_Pred_d - kth_X_Test_d, axis = 1) / numpy.linalg.norm(kth_X_Test_d, axis = 1);\n",
    "        mean_rel_error[d][k]                    = kth_Relative_Errors_d.max();\n",
    "\n",
    "        # Finally, compute the std of the frames of the prediction for the d'th derivative of the \n",
    "        # fom solution when we use the k'th combination of parameter values.\n",
    "        max_std[d][k]           = X_pred_samples[d][k, :, :].std(0).max();\n",
    "\n",
    "\n",
    "\n",
    "# Get the mean and std of each coefficient's distribution when we evaluate the posterior coefficient \n",
    "# distributions at each testing parameter value. We then reshape these arrays to have shape \n",
    "# (N(1), ... , N(n_p)), where N(k) is the number of distinct values of the k'th parameter in the \n",
    "# training set. The i(1), ... , i(n_p), j element of the d'th element of these lists will hold the \n",
    "# mean and std of the distribution of the j'th parameter when we use the i(k)'th value of the k'th \n",
    "# parameter.\n",
    "gp_pred_mean, gp_pred_std = GaussianProcess.eval_gp(gp_list, param_test);\n",
    "gp_pred_mean    = gp_pred_mean.reshape(test_grid_sizes + [-1]);\n",
    "gp_pred_std     = gp_pred_std.reshape(test_grid_sizes + [-1]);\n",
    "\n",
    "# Reshape each element of mean_rel_error and max_std has shape (N(1), ... , N(n_p)), where N(k) \n",
    "# is the number of distinct values of the k'th parameter in the training set. The i(1), ... , i(n_p) \n",
    "# element of the d'th element of these lists will hold the mean error and std of the prediction of \n",
    "# the d'th derivative of the fom solution when we use the i(k)'th value of the k'th parameter, \n",
    "# respectively.\n",
    "for d in range(n_IC):\n",
    "    mean_rel_error[d]   = mean_rel_error[d].reshape(test_grid_sizes);\n",
    "    max_std[d]          = max_std[d].reshape(test_grid_sizes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31c964",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389cdfb3",
   "metadata": {},
   "source": [
    "Plot mean and standard deviation of coefficient matrix.\n",
    "For SINDy of dimension 5, the coefficient matrix has a shape of (6, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  Plot;\n",
    "\n",
    "if(n_p == 2):\n",
    "    Plot.Plot_GP2d( p1_mesh     = test_meshgrid[0], \n",
    "                    p2_mesh     = test_meshgrid[1], \n",
    "                    gp_mean     = gp_pred_mean, \n",
    "                    gp_std      = gp_pred_std, \n",
    "                    param_train = param_train, \n",
    "                    param_names = param_names, \n",
    "                    n_cols      = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6073807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib;\n",
    "importlib.reload(Plot);\n",
    "\n",
    "for d in range(n_IC):\n",
    "    if(d == 0):\n",
    "        title_string : str = r'$max_{t} mean_{i} \\|x \\to \\left(\\tilde{u}_{\\xi^*}^{i}(t, x) - u(t, x) \\right) \\|/\\| x \\to u(t, x)\\|$';\n",
    "    else:\n",
    "        title_string : str = r'$max_{t} mean_{i} \\left\\|x \\to \\left( \\frac{d^{%d}}{dt^{%d}}\\tilde{u}_{\\xi^*}^{i}(t, x) - \\frac{d^{%d}}{dt^{%d}}u(t, x) \\right) \\right\\|$' % (d, d, d, d);\n",
    "\n",
    "\n",
    "    Plot.Plot_Heatmap2d(values          = mean_rel_error[d] * 100, \n",
    "                        p1_grid         = test_meshgrid[0][:, 0], \n",
    "                        p2_grid         = test_meshgrid[1][0, :], \n",
    "                        param_train     = param_train, \n",
    "                        n_init_train    = param_space.n_init_train, \n",
    "                        param_names     = param_names, \n",
    "                        title           = title_string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97720b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Plot);\n",
    "\n",
    "for d in range(n_IC):\n",
    "    if(d == 0):\n",
    "        title : str = r'$max_{(t, x)} \\sqrt{ V \\left[ \\tilde{u}_{\\xi^*} \\right] }$';\n",
    "    else:\n",
    "        title : str = r'$max_{(t, x)} \\sqrt{ V \\left[\\frac{d^{%d}}{dt^{%d}}\\tilde{u}_{\\xi^*} \\right] }$' % (d, d);\n",
    "\n",
    "\n",
    "    Plot.Plot_Heatmap2d(values          = max_std[d] * 100, \n",
    "                        p1_grid         = test_meshgrid[0][:, 0], \n",
    "                        p2_grid         = test_meshgrid[1][0, :], \n",
    "                        param_train     = param_train, \n",
    "                        n_init_train    = param_space.n_init_train, \n",
    "                        param_names     = param_names, \n",
    "                        title           = title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Plot);\n",
    "\n",
    "# Pick some parameter values.\n",
    "a           : float                 = 0.9;\n",
    "w           : float                 = 1.07; \n",
    "param_grid  : numpy.ndarray         = numpy.array([[a, w]]);\n",
    "\n",
    "# Get the predicted solution using this parameter value.\n",
    "X_True      : list[torch.Tensor]    = physics.solve(param_grid[0]);\n",
    "for d in range(n_IC):\n",
    "    X_True[d] = X_True[d].detach().squeeze().numpy();\n",
    "\n",
    "# Plot the predictions!\n",
    "Plot.Plot_Prediction(\n",
    "            model           = model, \n",
    "            physics         = physics, \n",
    "            latent_dynamics = latent_dynamics, \n",
    "            param_grid      = param_grid,\n",
    "            gp_list         = gp_list, \n",
    "            n_samples       = n_samples, \n",
    "            X_True          = X_True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ed21a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LaSDI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
